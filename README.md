# Data for Policy 2019

This repo contains my notes for the conference [Data for Policy](http://dataforpolicy.org/) 2019.

## Monday Pre-Conference Workshops

### Morning

#### Data Stewardship in Action: Workshop on Making Data Collaboratives Systematic, Sustainable and Responsible

Stefaan Verhulst

#### [Data Collaboratives](http://datacollaboratives.org/)

* 250 examples of the private and public sector work together with data.

* A whole spectrum to sharing data and collaboratives. From fully open data to fully shared results (with fully restricted data)

* Many ways to run a collaborative depending on several variables (openness, timing, type of work, focus, etc)

* Are there any evidence of what works better withing the spectrum of the conditionality matrix of open-restrictive/different levels of collaboratives? It varies on case-by-case scenarios. There is a paper in the making for guiding what strategy is better depending on the variables (e.g., scope, access, data, collaboration) you have for a project

* Big challenge to any collaborative sustainable

* A lot of data important for the public resides in the private sector. Reciprocity from the public sector is the main incentive for corporations to share some of the data. There is also reputation, doing research, social responsability, rataining of talent (data scientists in industry may be more motivated to stay in a company where they have access to data for the public good such as, for example, UNICEF)

* There is a large cultural challenge between herding data and sharing it. "Often people do not get promoted for sharing data, but because nothing bad happenned with the data"

* Does data sharing have to be free? We need to have the hard convo about financial sustainability

* There are also ethical considerations. Multiple risks: privacy, ethical, competitive

* With private sector it is helpful to ask for data in a customer-centric framework than in a data-centric way. Customer-centric: what questions are you interested in answering? why can't you? the data are not available. Hey, your customer needs these data.

* If you don't share any data,but only the insights from that data? Not solved. There is room for trusted organizations that audit the insights from data without disclosing the data.

#### [Data Stewardship](https://medium.com/data-stewards-network) - The role of the chief data steward

* Make data collaboratives: sustainable, sistematic, and responsible - a gobernance model

* Repository of contracts: Contractual wheel of data collaboration. To help the legal conversation about data and make it more systematic

* [The 100 questions initiative](https://the100questions.org)

* Trying to go beyond prototypes and make data use for public policy sustainable. 

* One way is to have a Data Stewards (in the interest of public interest) - a person within each organization that can connect with the data. Other functions: There is also a need to create the data marketplace + Build the community of practice

* The Cambridge Analytica made it clear that even partnership with academia can turn into disaster. It's important to have data stewards to know who to partner with

* The public sector can help making this work in the private sector in a self-regulatory framework by asking the private sector to make the private sector work on this (carrot/stick approach - the stick is the shadow of the public sector helping this happenning)

* Secondary use debate: data was collected for one purpose but insight is usually extracted as a secondary use of that data. The use for secondary analyses is a case GDPR does not talk about. 

* We already have chief data security officers. Now we would need to have the same need for data stewardship. National stats agencies are data stewards. There are connections to be made with them and a commmunity to build.

Slides available upon request

### Afternoon


#### Data Sharing & Data Trusts

Gefion Thuermer, Johanna Walker

* Follows with the previous workshop, but independent. More practical. Success cases and tips for sharing data.

#### Session 1: Why is data sharing important? - Johanna Walker

* Data sharing economy. Motivation: "data economy may increase to 739 billion euros by 2020"

* "Data sharing club" (yes, quite similar to belonging to a club where you pay a bit to belong, entrants may get in for free, if the fullfil some reqs) vs open/close platforms for sharing data

* Challenges to solve. Incentives, broader than industry sectors, conditions, match supply and demand, trust (to not abuse your data and behave responsibly with your data).

* Ecosystem examples. Data sharing incubators and caccelerators. Intearnational data spaces; BDVA-PPP I - space; ODI

* [Data Pitch](http://www.datapitch.eu) - a data sharing case study. European open, data/driven innovation program. Innovators, enterpeneurs, data providers, ...


* Data provider challenges: it took a year to get data providers involved, identify the data and problem to include in the pitch. 8 months to define challenge and review legal aspects of data. 4 months to agree on a contract. 2 months to obtain metadata sample


* Case: Greiner Packaging International3. Ended up matched with five innovators who are now working on advancing different areas of thier business. They had a person dedicated to advance data driven innovation - we could say it is a data steward


#### Session 2: Data sharing and trust

Kieron O'Hara, Jack Springman

* Results? Often, you look down the water and you just see the risks (i.e. sharks)

* Ethical data stewardship: regulation is not enough (...) Institutions for trust (e.g., Data trusts/data sharing clubs)

##### Data mobility infrastructure

* The data portability growth oportunity for the UK economy - 2018 report: 

* Advantages: economic benefits, accelerate innovation, healthier markets, improve productivity

* Issues: consumer services and applications, adaptives regulation, infrastructure, and two more

* Personal data mobility sandbox. BT, British Gas, Barclays BBC, fb. With *observers*: Centre for data ethics and innovations, consumers international dcms, ico, university of southampton. The purpose is to demonstrate safe data sharing for people to share their personal data.

* GDPR does not make it easy to share the data/data mobility between individuals and different institutions.

* From data portability do data mobility.A vision: using a data facilitator like "dgme" with apis from different companies (e.g., fb, spotify, etc) - individuals import/export their data from the different companies in a safe and ethical environment. it was important to test the user experience about perception of  security and privacy. 

* What do people/companies get in return? Value was discussed with data importers/provided.

* Report can be found at the [Ctrl-Shift website](http://www.ctrl-shift.co.uk)

* It has to be safe and valuable to share data.

#### Session 3: Increasing access to data while retaining trust

Jack Hardinges, Peter Wells, [Open Data Institute](http://theodi.org)

* ODI mission: works with companies andgovernments to build an open trusworthy data ecosystem.

* ODI vision: we want a world where data works for evyerone. Non-naive idealists. Long-term goal

* ODI works through the complete data sprectrum: smal/medium/(meaningless) big data - public, commercial, etc

* Data is infrastructure. We see it more when it is not working. It should be more boring than it usually is.

* Trust and trustworthiness is highly context-dependent.

* Which data access models give people increased access to data while retaining trust?

* Trust : A general definition of rust (Kieron O'Hara, 2012). BURRITOS model. *B*etter *U*nderstanding the *R*esponsibilities and *R*ationales *I*nforming *T*rustworthy *O*ptions for *S*haring, but a better way to talk about taxonnomy is "The map of data access" which will be published in about three weeks with a travel guide over the map

* For example, some areas of the map require a lot more exploration than others. For example the island Collaborator in the map. If you are in a given part of the map that others explored, the guide will give you hints on what worked for others and what didn't work at a practical level.

* A federation of data explorers? UoS, Datapitch, Govlab, data stweards, big firms, governments, etc

* Case study in the trust island in the map. Data trust as a legal structure that provides independente stewardship of data. The trustess/data stewards of the data trust take on responsibility for how data is used and shared, take liabilities.

* Several related examples: genomics england access commitee, office for nationals tats secure research service, NHS health research authority confidentiality advisory group, metadac, etc, etc, etc.

* Pilot projects: Civic (data about electric behicle for instance), food waste (and sales data), illegal wildlife trade (image and acoustic data). some of them had personal identification data. Multi-disciplinary team over three months.

* Challenges in increasing access to data: lack of value for business, concerns about reputation impact, las of resources to share data, who owns and has rights on the data, lack of standards, limited dta literacy and skills.

* Challenges in building data trusts: what is a data trust?, determining independence, financial sustainability, decision making open participatory and deliberative; lack of ecosystem maturity; how to demonstrate trustworthiness; use of dta trusts to steward personal data, avoiding technology/first solucions (poniendo el caballo adelante del carro?)

* Building data trusts: there is a 30-page guide on how to get this going online

Slides will be sent

## Tuesday: Conference

### Morning

#### Ethics 

Automating with Caution - Fabrizio, MVD, Uruguay

* People in the global south have stuff to say too - speaker biases

* AI in the public realm looks like a rich market with a lot of options. Not quite clear about some definitions, less for the lay man/woman in LatAm. Same happenned with Open Data

* AI: what's in a word. A simple way to consider it a constellation of methods incluidng ML, NLP, perception and reasoning. Some kind of automation.

* AI in practice: automation of processess, chatbosts in public services, detection of salient behaviours, / fraud, mapping territory, prediction of population behaviour in disasters or events

* What do we mean by bad practice - we are starting to see the people behind the algorithms. It may not be even sofisticated algos. Many times are people with low wages doing the work. This can lead to failure cases (e.g., cutting healthcare)

* What's so special about public sector.  State has to be accountable and fllow the law and abide by human rights and legal principles. The state must be able to explain its decisions. Official info that has leagla consequences on individuals. It's not just advertising... risks are a lot higher.

* Examples in the field - MVD example for predicting crime. They started using an algo dev in LA, USA and ended the agreement with the US company because they couldn't audit the algo. They developed their own algo in Uruguay now.

* Fail case in Argentina: Salta's case for predicting teen pregnancy. Identifying mostly poor women. A failure at a lot of levels. The experiment was dismissed thanks to the public buzz and open discussion about it.

* Success case in Argentina: Dymaxion Labs to identify the use of the territory using satellite images.

* Address five dimensions: need, infrastructure, ethical and regulatory framework, accountability, and evaluation. We need to discuss about all of this. We shouldn't be experimenting with humans without these rules being developped yet.

* Map showing that the Global South is mainly not exactly ready to move this forward. A lot of discussion must happenned.

* With low resources, we must prioritize. There is a human right framework that is fairly good, but not applied all the time.

* Automating with caution. We should think these things for the beguinning. 

Empowering people through informed consent. Informed consent and trust / Tessa Darbyshire, et al Oxford, UK

*  None in London has ever read the term and conditions. Privacy policies are aoften inaccesibily complex, hardly ever read and then rarely understood by most users. CAn you consider this consent?

* How informed is a user when thy agree to a privacy policy? Come on, we did gave you a privacy policy...

* Developpping tha empowers userst to better grant informed consent

* Stakeholders: legislators and researchers, service providers, users. Making this usable is very difficult.

* MozFest findings / open source. Biased due to their knowledge. Enforcemnt from a trusted third party, empowering users to maker their own decisions. Users are super lazy, but if yit adds extra time to your day, we don't care. But there is  a lot fo things people care about when they look these agreements closely. They find agreements excessive, vague and exclusive. Comapnies don't know they are doing this.

* Challenge for organizsations. Crystal clear from legal perspective to something that means something to participants.

* New Trust model: base/up. Transparency, inclusion, dialogue. the last part is the hardest.

* Opportunities. public commitement to privacy, opportunities for incluison, use plain English, challenge the business internally to work more with the open source community, make privacy feel like an interaction.

* Tools from open sources. Usableprivacy.org. terms of service didn't read. many did work. GTrusted third party: ToS / stickers, automatic tagging using machine learning. 

* Ploisis a viz tool to understanding this.

* Parsing and summarizing. privacy policies is specialised and not understandable. Wilson annotation scheme.

* Process: replacing a set of docs you dont understand by a number you dont understand doesnt help.

* Future: Which thir partier count as trusted third parties? how granular should trust cues be? (pass or fails, ribbon diagrams), which users want to be more informed and which consumers want a simpel trust

* Question: you do all this work and then what? Tessa: trying to work with the companies so they don't work against their customers. Fabrizio: There are some international fori. Connecting the policy makers with higher up politicians "watch dogs" can be a solution to this.



## Afternooon plenary

* Keynote - Ethics of AI and autonomoous decision making - Christoph Luetge, Technial University of Munich @chluetge

Opportunities of AI / telefmedicne. Rural depopulation and hecne rural services. uneven distribution of physicinas

* Care robots: amjor problem of ageing society. shortage on qualified healthcare personnel, solution bobots specifically designed for care tasks. Even more humanes? studies show that it is more humane to have robots assisting them in daily routine. it's better to have human beings intearcting in other ways.

* AI / big data. improved decisions based on more and better info. oslo reduced street lighting energy soncumption by 62% using big data. predictive crime mapping

* IoT: optimazation of al physical en for cmfort and productivity. reduction of costs, time gain. improved decsion making> do human beings really make better decisions on averac?

* Smart grid: major problem, globally increasing energy demand.

* autonomous driving: ethical problem of cards> high falttality rates. 90/95% of car accidents caused by humann error. autnonomous cars as solution to reduce car accidents. in germany this would mean ultimately saving around 3000 lives /year

* Examples from health care sector> paradigm shift in healthcare, through increasing availability of data and fast advancemente of analytics techniques. 
* strokes . ai applications in cardiology for early detection, teratment and outcome prediction

* Cancer: identify precancerous statesges. NCI, 2019 AI better at identifying precancer than human expert reviewer, AI by goog> LYNA

* Reproductive health education> chatbot in Pakistan for women to ask questions regarding reproductive health. a means to address a taboo subject and empowerrment women in Pakistan. has helped in emergency cases to get medicl aattention

Challenges of AI:

* technical challenges. dependence on the accuracy, danger of technical errors. Loss of onces autonomous decisons.
* increased vulnerability against cyber attacks, danger of cyber wars
* privacy and dnager of data misuse ( GDPR, perceptions of the problem(
* Digital literacy / educaiton in digital literacy often lacking. it varies from country to country. even in Germany.

* Fakes and manipulations. deepfakes / software to generate or edit video material creating a fake video of a politician speech. DeepMasterPrints, generate fake finger prints to unlock devices. Facke social media bots. Prventing crime> automated blackmailing, intelligent hacking attacks

* Specific examples> tritter blocks accounts based on algos due to some keywords. it was unclocked the next day. Hiring softwared used by Amazon 2014/2017: discrimination aginst women. Airbnb smart pricing algos may widen ethnic gap

* Social challenges> may devalue human skills. reducing human responsibility, ....

* Public opinion> what do people think about AI? 41% support in the US, 22% strongly oppose (Zhang/dafoe, US, 2019)

* Most prioritized governmental challenges> ai assisted surveillance violating privacy and civil liberties, to spread fake online content, cyber attacks, protection of data privacy. Important challenges for over 50% of raters and for the next 10 years in the US

* Most trusted> university researchers and the US military. Least trusted is Facebook. No orgs for which the average respondent had @a fair amount of confidence" Conclusion: We need more trust

* Trustworthy AI. Development, deployment and use should resjpect fundamental rights and applicable regulation, as well as core principles and values ensuring an ethical purpose. should be technically robust and reliable. foster publics trust in AI, society needs a widely accesible and reliable mechanism of redress for harms inflicted.

* Initiatives proposing principles on AI (OECD, May 2019 adopted). AI should be fair, transparent and accountable. IEEEE Thically aligned design. General principles human rights, well being, data agency, effectiveneess, transparency, acountabilty, awareness of misuse, competence.  Ethics certificationi program for autnonomous and intelligent systems (ECPAIS). But "of course China will take over and this is over" FALSE. There are regulations about rights in China as of 2019. Cybersecutrity Law, soncumer rights protection act, 9th ammendment of criminal law. Privacy is not a concept in China. Decisions by National people's congress. No unified frameork yet. The concepts are in the agenda and evolving as generations evolve.

* Further exampels. UK digital competitino expert panel. San Francisco Board of Supervisors ban of facila recognition by police. German BaFin. France Canada Panel on AI

* GDPR. Right to the protection fo personal data is not an absolute right. right to data portability allowing people to freely trade tehir data. World wide this varies, Europe could learn from each other.

* AI4People European initiative will release a paper in a month with ethics principles. Beneficence, non/maleficence, autonomy , justice, explicability - no new principles, but very important. Human centered approach AI4People.

* Technical methods to implement the core principles for AI. documenting decisons, explanation, traceability and auditability. Non tehcnical methods> regulation, standardization, accountability governance, codes of conduct, education and awareness, etc

* Second European approach First Ethics committee for autonomous driving. Germany. The liability when the car drives alone it is for the company tha manufactures the car and runs the algos. In the event of unavoidable accidente situaations, any distinction based on personal features is strictly prohibited. It is also prohibitd to offset victims against one another. General programming to reduc the number of personal injuries may be justitiable. Those partiers involved in the generation of mobility risks must not sacrifice non/involved partiers. Rules 9

* The autonomous driving example has some lessons to teach us. Autonomous driving rules need to get standardized across countries. 

* A business ethics and regulation perspective. How ethics and regulation fit into a competitive market for AI? Conditions of competiions> sufficient among tech companies? direct competition> mobile devices, hunt of user data,. Indirectly> google vs microsoft and ibm in the run for bigdata analysis. alternatives to amazon. is there real competition there?

* Uber/Lyft. Differing perceptions in parts of Europe and other regions. Public discussion often uses ethical arguments (working conditions, wage level, tax evacion of drivers) - is it just cab drivers lobbying against?

* REleasing an autonomous car before competitiros even if driving software has not been adequately tested. Bending data protection rules in order to gather more data than competitors. Being sloppy with data security in order to get an advantage.

* Creating shared value (Porter and Kramer 2011) this is sometimes better than regulation. having policies and operrating practices tha enhance the competitiveness of a company while advancing the economic and social conditions at the same times within the community where it operates.

* Doing good by doing well. Long/term calculations needed. consider systematically the interests of others who may be relevant for the company's future. reputation and penalty reduction through risk management throug early warning.

* actively taking on ethical responsibilty without changes in law has become bothe a necessity and an advantae in competition for many companies in raising profits, in innovation capability, in better risk management. several references.

* Jean Tirole Nobel Prize 2014 on digital markets and regulation. We neeed a participative antitrust inwhich the industry or other parties propose possible regulation, and the antitrust authorities respond to it (Tirole 2018). 

* Political and scientific initiatives> expert groups IEEE, AI HLEG, AI4People

* Trust in AI is key. more research, more data to assess algos impact, rething the human/machine collaboration instead of AI replacin humnas, guidelines and frameworks for ethical AI. Tools for companines to follow ethical frameworks and establish tructs. Focus on meeting societal acceptance.

* Q: how all of this gets to gobernment? well, we still have to have that convo. we've been working on it a lot, but we have to keep working on it and have a lot of conversations still for this to get to government

* There is a lot of nuance that goes into privacy and the use of data. It is not the same that the gob uses, for example, Alexa data for a service than to solve a crime. We may get to Alexa data to solve the crime, but not otherwise. We need to be more creative and think hard about nuances.

* Algo transparency and the interplay with intellectual property? Transparency is the wrong concept. Making the code transparent may not help. Most expert groups say that we need to get to something like explicability instead of transparency. Transparency does not achieve much. We would need to understand why the algo came up with a given decision, and that usually cant be done just with the code. Explicability (to be designed) is a better concept than transparency.


Session 2d (MQ 101): Data-Driven Policy
Chair: Jack Tindale (@JackTindale), Policy Connect (@Policy_Connect)

"Policy Priority Inference: A Computational Approach for the Discovery, Evaluation and Prescription of Development Strategies"; Omar Guerrero*
(@guerrero_oa) - UCL & The Alan Turing Institute, UK (@turinginst), and Gonzalo Castañeda - CIDE, Mexico.

* How to reach the sustainable dev goals? how do you prioritize your resources? Tool for the gobs to reach certain indicators. How do we do it? it can be very complex.

* Mental model behind the tool. Policy prioritisation. Gob wants to ameliorate education so outcomes improve, but you can also have plain corruption. It's never 1 to 1. There are inputs (resources) and outcomes. we will focus only on outcomes, not enough data for the inputs yet. But of course there are interactions of ed with health and infrastructre as transportation. So the Ed can improve due to ogther public policies which obscure the one policy we want to study in Ed. and the network is huge.

* Tool, agent-driven. time series. with development indicators (country specific), network (socioecon context), development goals (multidim targets) <- inputs.

* Example. Retrospective policy priorities + Prospective policy priorities - study published some years ago. Casta#eda, chavez and guerrero 2018. Priorities change if you want to imitate other countries, well... context matter - the paper shows how.

* quantifying policy coherence. are gov policy priorites coherent with its goals? -1 inchoerent vs 1 coherent. Guerrero & Casta#eda 2018, the index for Mexico looks incoherent, but has success cases. The index works in real world.

turing.ac.uk/research/research-projects/policy-priority-inference

Session 2b (G01): Sustainability 1
Chair: Derek Wyatt, UK

[43] "Using data for risk management policy – introducing the data-oriented approach into policy-making in Japan on food safety, drug safety, earthquake
disaster prevention, and climate change"; Yasushi Sato* - Niigata University, Keiko Matsuo - Japan Science and Technology Agency, and Noel Kikuchi - National Graduate Institute for Policy Studies.

* Scientific advice was important. 

* Why data-oriented approach underutilized in risk managemente policy making? data/oriented approach vs mechanism/oriented approach. There is not a dichotomy but they are different.

*  Examples from other fields of data-oriented approaches. Food safety QSAR quantitative structure activity relationsips. Drug safety,real world data and pharmacometrics. Earthquake, statittical seismology and various geological data. Climate change> mechanism oriented and data oriented approaches are effectively used in complementary ways obtaining local scale climate from global models and local policy making.

* Data availability and model dependability (challenges) different depending on each field. Regulation of vital risks such as drug safety and food safety is high in imperative for certitude and sensitiviy for litigation and high for the data availability and model dependability. Climate change and earthquake, responses to chronic risks are both low in these dimensions.

* More interdisciplinary is being observed in the data/oriented approach in climate change.

* Conclusions. each policy field can learn from other fileds in endeavoring to incorporate the data-oriented approach into risk management policy- making. In the field of climate change, the data oriented and mech oriented approaches have been integrated in relatively matured ways. as the data oriented aproach is incorporated into the process of policy making, mechanisms for collaboration among diverse types of scientistis and policy makers as well as communication with the public, is needed.

* the distinction between data-oriented approach and model-oriented approach is not always clear cut.

* how do we implement these science-based knowledge into action for climate change? adaptation has been important for climate change in the last 15 years. In Japan, this is true in the last few years, mostly in the last year. To implement the policies trust and downscaling the info to local places from trusted sources. How do you enforce mitigation, though? 

[122] "WHO’s transformation changing generation and use of health data to drive impact of policy actions"; Doo Hee You*, Tina Purnat and Samira Asma - World Health Organization, Switzerland (@WHO).

Data analytics and delivery for impact

What has been donw by WHO in the flow of the data process to make the max impact of policy making actions

1. what has been donw by UN and who general programme of work. #globalgoals SDGs and health related goals have put a demand on production of reliable health data, much of which who is a custodian of. 17 indicators, poverty hunger, health quality of education, gender equality, jobs. For the countries to informs their policy making with best evidence, they neeed stronger and coordinated info systems for healt. see un and sdg website. who looks into de public health data.

* WHO director general 2019-2023 goal is to ensure> a billion more people have universal health coverage. a billion more people are protected from health emergencies and a further billion are living with better health and wellbeing.

* 46 targets and indicators including all meta data and data collected in the who website. those targets will be used to calculate the advance towards the goals. overarching goal, measured by healthy life expectancy (HALE). all of this globally.

* Why WHO reforms? to empower member states and catalyze change so taht data and health info are used systematicllay and effectively to set measurable goals, drive continuous helath improvement and impact policy and progrmme change. Process> regional consultations, online sonsultation and mission briefings. Feedback> reducte reporting burden on countries, disaggregate data to report on inequalities (to better target interventions), support country capacity and sustainable systems

* WHO is> filling data gaps (provide tools for surveys, health info systems), modernizing data flow and delivering for impact.

* Some high income cuntries such as canada or australia, western europe are not reporting data because likely that is not a problem for them. but this does not allow this approach to be global. likely they are autosufficient. on the other hand there are countries that the capacity is not available. WHO is trying to address both ends of the spectrum.

* Modernize data flow. until now it is done through email with excel or a link when the data is very big. the workflow right now is old and has a high area for improvement.

* Delivery for impact. Innovative concept and comitment. Frequent follow up and evaluation for country policy dialogue partnering. Developing and innovative process the way it uses data in its work and governance. it is the first UN agency and one of the oldest that tries such a major comprehensive change. 

* Future. need for better operation and health data utilization. achieving impact in countries, bringing the work of who closer to the country office. being more agile in response to change. satify member states demand on higher transparency of who work and actions such as sharing the code.

* Inputs? ddi@who.int

* What incentives are you giving to self suficient countries? no simple answer.


Session 3c (G02): Data Practices, Lessons and Challenges
Chair: Bilal Gokpinar, University College London

[24] "Managing Personalization-Privacy Paradox of Digital Services: A Systematic Literature Review"; Ming-Wei Hsu*, Glenn Parry, Alex Kharlamov - University of the West England, UK.

* tensions arise when using data for personalisation. privay, control over access to personal info. privacy paradox, people say they are concerned about privacy but in practice they share all of their data for free. personalisation, better customer experience.

* how do we find balance_ personalisation/privacy pardox. firms need personal info to provide personalised services, consumers express that they have privacy concerns, in seeking to create a personalised service to gain customers, firms may lose customers

* Systematic literature review to approach this paradox based on 45 papers. See paper submitted to d4p for details on methods and fine description of findings.


Session 3a (JBR): Privacy 1
Chair: Anil Bharath, Imperial College London (@imperialcollege)

"Data protection issues in cross-border interoperability of EHRs systems withing the European Union"; Giorgia Bincoletto (@GiorgiaBinco) - University of
Bologna and University of Luxembourg, Italy (@uni_lu_FDEF & @unibomagazine).

* EHR electronic health record. 

1. policy context. 2011 directive - patients rights in cross border healthcare. EU policies for the digital single market goes to the transformation of health and care policy. areas of action> enabling EU citizens to access and share their health data securely across member states. barrier> interoperability. 

2. cross border interoperability of ehr systems. what is it? hability of a system A and B communicate and share info wo any effort for all generated data (eg clinical data, med history, patient details, labs, prescriptions). it implies many levels> technical, semantic, organizational and legal levels. urgent need of open exchange formats and hoarmonised standrds on health data quality and reliability privacy and security.

3. new recs of the EU commission released freb 2019. European electronic health record exchange format. principles for access and the exchange, set of technical specs and process and best practices. high importance to privacy and data protection concerns, for instance principles of data protection adn confidentiality and a citizen centric approach by design. The evolution of this is in private hands of those that develp EHR systems

4. data protection concerns and obligations.  huge amount of data and multiple processing. special category of data, health data. various data protection principles and rights. organisational level concerns and obligations> different data controllers and processors, legal grounds and explicit consent, info to the patient, the purpose limitation of the further processing, time accuracy principle, documentation and accountabiliity. technical level> data minimisation adn pseudonymisation, time lmimitations to the storage, the access mechanisms, the security tools and standars, data protection by design and by default

5. The progress to achieve interoperability stays with each state, but it is a priority in the dev of the national and regional EHR. EHR systems should be designed ex ante to ensure complicance with data protection rules. 


[85] "Towards Citizens’ Control Over Data? Exploring Contradictory Trends in the Emerging Regulatory Environment of Personal Data"; Arne Hintz (@arne_hz) - Cardiff University, UK (@cardiffuni).

* Broad strokes of policy trends from DAta Justice Labe, exploring social justice in an age of datafication.

* Policy frameworks for digital platforms moving from openness to inclusion. The explotation use of data has gone too far (eg cambridge analytica), personal data should be respected and used appropriately.

* Data policies project. investigates trends in policy change, citizen oriented policy frameworks, focus on uk and EU> national law and regional regulations like gdpr.

* Methods> document analysis> review of academic lit, stakeholder statements, interviews with stakeholders> government, business, and civil society

* People's control over data? user empowerment> info rights * like right to explanation(, access rights and data portability, consent requirements. Protections and restrictions of explotation of peoples data> purpose limitation, restrictions to profiling and automated decision making. data collection> data retention, communications interception, internet connection records, age verification, data sharing... all are expanding.

* so on one hand we must increase control and user empowermentt vs increase in institutional data collection and sharing. This is not only happenning int eh EU, Australia too for instance.

* components of citizen oriented data policy. Regulate data collection vs regulate uses< restricting collection remains crucial. User empowerment vs legal restrictions< informed user is unrealistic scenario, cant be core of data policy as research has repeatedly shown (eg consent fallacy, consent is disempowering rather than impowering - digital resignation). Types of data regulated: inferred/derived data. focus on personal data is *not* enough. inferred data will be increasingly the focus of data policy. Individual vs collective data: models for collective data control.

* towards democratic auditing: civic particpation in the scoring society. current research just starting. will talk about it next year.


[98] “The role of technology in governance: the example of Privacy Enhancing Technologies”; Natasha McCarthy* (@ntshmccrthy) and Franck Fourniol - The
Royal Society, UK (@RoyalSociety).

* based a reports published recently. 

* tensions: benefits and risks in data use. 4 tensions: making use of data vs respecting spheres of privacy. providing ways to exercise reasonable control over data vs encouraging data sharing for private and public benefit. incentivising innovative uses of data vs ensuring that such data can be traded and transferred in mutually beneficial ways. promoting and distributing the benefits of data use fairly across society vs ensuring acceptable levels of risk for individuals and communities.

* Role of PETs in addressing tensions. there was no tech that could address and manage all of these tensions. it's quite context dependent. many combined may be needed. More in the report. there may be differnt stages of the process and reasons of why how to manage these tensions. 5 different techs (incomplete, but these are the one reported because they seem most interested coming from  different fields like crypto people or stats people, etc). Addressing tension 2: personal data stores, apps that provide individuals with access and control over the data they generate, covered by the first talk in this session. Tension 1 + 2: homomorphic encryption and trusted execution environments (secure hardware). Tension 3: secure multi party computation> computing on combined data with no need for a trusted third party nor revealing own private input. Tension 1 +4> differential privacy> releasing the output of an anlysis without revealing if a specific individual/entity is in the input - math definition of privacy, allows you to reasoned mathematically on how much privacy you want at different levels.

* a lot more use cases in the report.

* Limitations: current technical constraints, and general limits in PETs deliverings ethical use of data. There costs using PETs. different levels of readiness.

* Enabling appropriate uptake and development of PETs. How far can PETs deliver ethical use of data? Thc is not the silver bullet. setting a privacy budget is a governance decision. the time and energy costs of PETs encourage extra scrutiny. should we be collectin or using the data at all_ Many ethical questions arise beyond privacy risks (eg, is the purpose of data use socially beneficial?, is it fair?, has the data been collect appropriately?)

* Enabling appropriate uptake and development of PETS. The RSS identified three areas. See the report for more.


Wednesday, 12 June 2019

11:00 – 12:00 Keynote Lecture 2 (JBR)
"How to tell when a tech is not ready for government" – supported by GovTech Lab
Jon Crowcroft (@tforcworc), University of Cambridge (@Cambridge_Uni) & Alan Turing Institute (@turinginst)
Chair: Innar Liiv (@innarliiv), Tallinn University of Technology, Estonia (@TallinnTech)
GovTech Lab (@GovTechLab) Introduction – Tom Wilkinson (DFID) and Giles Pavey (Unilever)

* super provocative keynote with a lot of hot points about "established truth"

* usually, obviously, whenthe governments not ready for tech. but more seriously techno optimist oversell readiness (eg internet 1980 versus web 1992, broadband access 2000 vs smart phone 2007, use of internet for hospital booking reminders - still not used, using sms now, the right tech; use of babylon systems for triasge 2018, wellbeing/ fitness dat from accelerometer, when?; nhs supply like pharma or dressings chains, when? All of that was supposed to be *fast*. 

* Ancient history> internet, email available & negotiable ; payment & funds txfer, paypal, musk was the first 1; web> transparency, publishing transport, energy, crime data; cloud affordable compute&analytics, but late to the game.

* With examples from dlt, ml&ai,iot. 1. distributed ledger technology, 2 machine lerninng and ai, 3 internet of things. For people interested in sustainability, none of these technologies were sustainanble when they started for many reasons, including legal reasons. Machine learning can be sustainable, but its more advanced techniques like deep learning are not that sustainable, it requires tons of tagged data and tons of processing gpus, with a large carbon print. It does not escalate to public policy... imagine increasing the carbon footprint while modeling climate for instance...

* IoT can be a massive fail in many places - heard about printer setup? what hope can we have with coffee machines hooked to the internet when sometimes even the internet may not get a good signal. somehow some people are finding ways to make realiable things work worse than now by including internet in them.

* dlt. do not mix up cryptocurrency and blockchain. immutable record of transations, but so is a database. samart contracts, but so was ecommerce. why not gov? 3 essential requirements, decentralised? nope. no single point of trust? nope Long term persistent? maybe

* dlt #2. ask someone peddling blockchain: what transaction rate do you support (read/write)?, what is the latency per transaction commit? where is your open source/spec repo? If government is ready for the huge numbers that different use cases can generate, then it is ready...

* ml/ai. do not mix up ml and ai. ml is just better stats with bigger faster compute/storage, please use, more! Already used in much gov. but what of ai, anything that isn't explainable. how would gov use black boxes (#rant about deep learning, of course :-D ), ever, pray? The first implementation of MCMC was 75 years ago, AI? hmmm, nothing new under the sun, or at least not so many things are that new after all.

* putting technology into work that can harm people (eg false positives in sentencing) is something to take into account for readiness.

* ml/ai. ask an ai peddler> what's your interpretability model? how did you de bias your training data (gem: "try sending white people to jail and see what happens with bias" )? where are your reprodicability (reproducibility + replicability - brilliant) results? if all of these can be answer, the tech may be ready for gov. otherwise, not a great idea.

* IoT. do not mix up internet (of things) and smart X. for x = home, car, city. Most IoT systems are silos, cctv, smart meter, fitness monitor&actuator; for good reasons, not just privacy, *safety* is paramount  - car brakes, defibrilator, etc. What would gov do: regulate safety, please... eg liability if dont match MUDs, require data minimisation

* IoT#2. Ask to IoT dealer> where are your product liability statements? waht are the published APIs for me to integrate with other IoT products? What are your software update&suppport plans 6-10 years now for any current product? OMG, compatibility! Sustainability over time... imaginge your washing machine hacked.

* generic gov tech lessons. dont listen to academics, massively too early. dont listen to industry, massively too late. especially dont listen to consultants, massively too expensive. _so who do you listen to? all of the above, with a pinch of salt._ hire a lot of people with different literacy on computer, stats, security, and domain experts too. 




09:30 – 10:30 Parallel Session 4
Session 4a (JBR): Hands-on-Data: Artificial intelligence for the design of public policy in Latin America
Chair: Tom Smith (@_datasmith), Office for National Statistics, UK (@DataSciCampus)


[80a] "Hands-on-Data: Description, lessons learned, and future directions of a speedy alternative to integrate artificial intelligence into the design of public policies in Latin America"; Lucila Berniell* (@luberniell), Laura Acion (@_lacion_) and Walter Sosa-Escudero (@wsosaescudero) - CAF, CONICET-UBA and Fundación Sadosky, CONICET-UdeSA, Argentina, respectively (@funsadosky & @institcalculo).


[80b] "Computing accessibility metrics for Argentina", Carlos Sarraute (@ch4rleston) - Grandata, Argentina (@GrandataLabs).


[80c] "Using data science to improve public transport in the city of Córdoba (Argentina)"; Andres Vazquez (@avdata99) - Municipality of Cordoba,
Information Systems and Innovation, Argentina (@MuniCba).


